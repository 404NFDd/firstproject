import { XMLParser } from "fast-xml-parser"
import type { Prisma } from "@prisma/client"
import { prisma } from "@/lib/prisma"

const NEWS_API_ENDPOINT = "https://newsapi.org/v2/top-headlines"
const NEWS_API_COUNTRY = "kr"
const NAVER_SEARCH_API_ENDPOINT = "https://openapi.naver.com/v1/search/news.json"

export const SUPPORTED_NEWS_CATEGORIES = [
  "general",
  "business",
  "entertainment",
  "health",
  "science",
  "sports",
  "technology",
  "developer",
] as const

type NewsCategory = (typeof SUPPORTED_NEWS_CATEGORIES)[number]

// ë„¤ì´ë²„ ê²€ìƒ‰ API ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ì–´ ë§¤í•‘
const NAVER_CATEGORY_QUERIES: Record<NewsCategory, string[]> = {
  general: ["ë‰´ìŠ¤", "ì†ë³´", "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤"],
  business: ["ê²½ì œ", "ë¹„ì¦ˆë‹ˆìŠ¤", "ê¸ˆìœµ", "ì£¼ì‹"],
  entertainment: ["ì—°ì˜ˆ", "ì—”í„°í…Œì¸ë¨¼íŠ¸", "ë°©ì†¡"],
  health: ["ê±´ê°•", "ì˜ë£Œ", "ë³´ê±´"],
  science: ["ê³¼í•™", "ê¸°ìˆ ", "ì—°êµ¬"],
  sports: ["ìŠ¤í¬ì¸ ", "ìš´ë™", "ê²½ê¸°"],
  technology: ["IT", "ê¸°ìˆ ", "í…Œí¬", "ì†Œí”„íŠ¸ì›¨ì–´"],
  developer: ["ê°œë°œì", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ", "ê°œë°œ ì´ìŠˆ", "í”„ë¡œê·¸ë˜ë¨¸", "ê°œë°œì ë‰´ìŠ¤"],
}

const CATEGORY_PRIORITY_WEIGHT: Record<string, number> = {
  general: 10,
  business: 8,
  entertainment: 4,
  health: 6,
  science: 7,
  sports: 5,
  technology: 9,
  developer: 9,
}

const RSS_FEEDS = [
  { category: "technology", url: "https://www.techmeme.com/feed.xml" },
  { category: "business", url: "https://feeds.bbci.co.uk/news/business/rss.xml" },
  { category: "science", url: "https://www.sciencemag.org/rss/news_current.xml" },
  { category: "general", url: "https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml" },
  { category: "developer", url: "https://dev.to/feed" },
  { category: "developer", url: "https://news.ycombinator.com/rss" },
]

const xmlParser = new XMLParser({
  ignoreAttributes: false,
  attributeNamePrefix: "",
  textNodeName: "value",
})

type NormalizedArticle = {
  title: string
  description?: string
  content?: string
  imageUrl?: string
  sourceUrl?: string
  source: string
  author?: string
  publishedAt: Date
  category: string
  priority: number
}

type NewsQuery = {
  page?: number
  limit?: number
  category?: string
  search?: string
  sort?: "latest" | "priority" | "popular"
  minPriority?: number
}

export type NewsIngestResult = {
  fetched: number
  persisted: number
  skipped: number
}

const REQUIRED_ENV_KEY = "NEWS_API_KEY"
const NAVER_CLIENT_ID_KEY = "CLIENT_ID"
const NAVER_CLIENT_SECRET_KEY = "CLIENT_SECRET"

const DEFAULT_QUERY: Required<Pick<NewsQuery, "limit" | "page" | "sort">> = {
  page: 1,
  limit: 12,
  sort: "latest",
}

const normalizeCategory = (category?: string | null): NewsCategory => {
  if (!category) return "general"
  return (SUPPORTED_NEWS_CATEGORIES.includes(category as NewsCategory) ? category : "general") as NewsCategory
}

const sanitizeString = (value?: string | null) => value?.trim() || undefined

// ê°œë°œì ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€ í•¨ìˆ˜
function detectDeveloperCategory(article: { title: string; description?: string; content?: string }): boolean {
  const keywords = [
    "ê°œë°œì", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ", "ê°œë°œ ì´ìŠˆ", "í”„ë¡œê·¸ë˜ë¨¸", "ê°œë°œì ë‰´ìŠ¤",
    "developer", "programming", "coding", "software engineer", "software development",
    "í”„ë¡ íŠ¸ì—”ë“œ", "ë°±ì—”ë“œ", "í’€ìŠ¤íƒ", "frontend", "backend", "fullstack",
    "ì•Œê³ ë¦¬ì¦˜", "ë°ì´í„°êµ¬ì¡°", "algorithm", "data structure",
    "ê°œë°œ ë„êµ¬", "IDE", "ì—ë””í„°", "ê°œë°œ í™˜ê²½",
    "ì˜¤í”ˆì†ŒìŠ¤", "open source", "github", "git",
    "ìŠ¤íƒ€íŠ¸ì—… ê°œë°œ", "ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ ", "startup tech",
  ]
  const text = `${article.title} ${article.description || ""} ${article.content || ""}`.toLowerCase()
  return keywords.some((keyword) => text.includes(keyword.toLowerCase()))
}

// ê°„ë‹¨í•œ í•œêµ­ì–´ ê°ì§€ í•¨ìˆ˜ (í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„ ì²´í¬)
function isKorean(text: string): boolean {
  // í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: AC00-D7AF (ì™„ì„±í˜•), 1100-11FF (ìëª¨), 3130-318F (í˜¸í™˜ ìëª¨)
  const koreanRegex = /[\uAC00-\uD7AF\u1100-\u11FF\u3130-\u318F]/
  return koreanRegex.test(text)
}

// Google Cloud Translation APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
export async function translateToKorean(text: string | undefined | null): Promise<string | undefined> {
  if (!text || !text.trim()) return undefined

  // ì´ë¯¸ í•œêµ­ì–´ì¸ ê²½ìš° ë²ˆì—­í•˜ì§€ ì•ŠìŒ
  if (isKorean(text)) {
    return text
  }

  const apiKey = process.env.GOOGLE_TRANSLATE_API_KEY
  if (!apiKey) {
    console.warn("âš ï¸  GOOGLE_TRANSLATE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë²ˆì—­ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    return text // ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜
  }

  try {
    // ê°œí–‰ ë¬¸ì í™•ì¸ (ë””ë²„ê¹…ìš©)
    const hasNewlines = text.includes("\n")
    if (hasNewlines) {
      console.log(`ğŸ“ ë²ˆì—­ ì „ í…ìŠ¤íŠ¸ì— ê°œí–‰ ë°œê²¬: ${text.split("\n").length - 1}ê°œ`)
    }

    // ê°œí–‰ ë¬¸ìë¥¼ ì„ì‹œ ë§ˆì»¤ë¡œ ì¹˜í™˜í•˜ì—¬ ë³´ì¡´
    const NEWLINE_MARKER = "___NEWLINE___"
    const DOUBLE_NEWLINE_MARKER = "___DOUBLE_NEWLINE___"

    // ì—°ì†ëœ ê°œí–‰ì„ ë¨¼ì € ì²˜ë¦¬ (2ê°œ ì´ìƒ)
    let textWithMarkers = text.replace(/\n\n+/g, DOUBLE_NEWLINE_MARKER)
    // ë‹¨ì¼ ê°œí–‰ ì²˜ë¦¬
    textWithMarkers = textWithMarkers.replace(/\n/g, NEWLINE_MARKER)

    // Google Cloud Translation API v2 REST API ì‚¬ìš©
    // ë¬¸ì„œ ì°¸ê³ : https://docs.cloud.google.com/translate/docs/reference/rpc/google.cloud.translate.v2
    // qëŠ” ë°°ì—´ë¡œ ì „ë‹¬ (ìµœëŒ€ 128ê°œ), formatì€ "text" (plain text)
    const url = `https://translation.googleapis.com/language/translate/v2?key=${encodeURIComponent(apiKey)}`

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        q: [textWithMarkers], // TranslateTextRequest.q[] - ë°°ì—´ë¡œ ì „ë‹¬ (ìµœëŒ€ 128ê°œ)
        target: "ko", // TranslateTextRequest.target - íƒ€ê²Ÿ ì–¸ì–´ (í•„ìˆ˜)
        format: "text", // TranslateTextRequest.format - "html" ë˜ëŠ” "text" (ê¸°ë³¸ê°’: "html")
        // sourceëŠ” ìƒëµí•˜ë©´ ìë™ ê°ì§€ (TranslateTextRequest.source - ì„ íƒì‚¬í•­)
      }),
      signal: AbortSignal.timeout(10000), // 10ì´ˆ íƒ€ì„ì•„ì›ƒ
    })

    if (!response.ok) {
      const errorText = await response.text().catch(() => "")
      console.error(`âš ï¸  ë²ˆì—­ API ìš”ì²­ ì‹¤íŒ¨: ${response.status} ${response.statusText}`)
      if (errorText) {
        try {
          const errorData = JSON.parse(errorText)
          console.error(`   ì˜¤ë¥˜ ë‚´ìš©:`, errorData.error?.message || errorText.substring(0, 200))
        } catch {
          console.error(`   ì‘ë‹µ ë‚´ìš©: ${errorText.substring(0, 200)}`)
        }
      }
      return text // ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜
    }

    const data = await response.json()

    // ì—ëŸ¬ ì‘ë‹µ ì²´í¬
    if (data.error) {
      console.error(`âš ï¸  ë²ˆì—­ API ì˜¤ë¥˜:`, data.error)
      return text
    }

    // TranslateTextResponse í˜•ì‹: data.translations[].translated_text
    // REST APIëŠ” snake_caseë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‘ ê°€ì§€ í˜•ì‹ ëª¨ë‘ í™•ì¸
    const translation = data?.data?.translations?.[0]
    const translatedText = translation?.translated_text || translation?.translatedText

    if (translatedText) {
      // ë§ˆì»¤ë¥¼ ë‹¤ì‹œ ê°œí–‰ ë¬¸ìë¡œ ë³µì›
      let restoredText = translatedText
        .replace(new RegExp(DOUBLE_NEWLINE_MARKER.replace(/[.*+?^${}()|[\]\\]/g, "\\$&"), "g"), "\n\n")
        .replace(new RegExp(NEWLINE_MARKER.replace(/[.*+?^${}()|[\]\\]/g, "\\$&"), "g"), "\n")

      // ë³µì› í›„ ê°œí–‰ í™•ì¸ (ë””ë²„ê¹…ìš©)
      if (hasNewlines) {
        const restoredNewlines = restoredText.split("\n").length - 1
        console.log(`âœ… ë²ˆì—­ í›„ ê°œí–‰ ë³µì›: ${restoredNewlines}ê°œ`)
      }

      return restoredText
    }

    return text // ë²ˆì—­ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë¬¸ ë°˜í™˜
  } catch (error) {
    console.error("âš ï¸  ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error)
    if (error instanceof Error) {
      console.error(`   ì˜¤ë¥˜ ë©”ì‹œì§€: ${error.message}`)
    }
    return text // ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë¬¸ ë°˜í™˜
  }
}

// HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ê°œí–‰ ë³´ì¡´ ì˜µì…˜)
const stripHtmlTags = (html?: string | null, preserveNewlines = false): string | undefined => {
  if (!html) return undefined

  let text = html

  // HTML ë¸”ë¡ íƒœê·¸ë¥¼ ê°œí–‰ìœ¼ë¡œ ë³€í™˜ (ê°œí–‰ ë³´ì¡´ ëª¨ë“œì¼ ë•Œ)
  if (preserveNewlines) {
    // ë¸”ë¡ íƒœê·¸ë¥¼ ê°œí–‰ìœ¼ë¡œ ë³€í™˜
    text = text
      .replace(/<\/p>/gi, "\n\n")  // </p> -> ë‘ ê°œí–‰
      .replace(/<p[^>]*>/gi, "")   // <p> ì œê±°
      .replace(/<\/div>/gi, "\n")   // </div> -> ê°œí–‰
      .replace(/<div[^>]*>/gi, "")  // <div> ì œê±°
      .replace(/<br\s*\/?>/gi, "\n") // <br> -> ê°œí–‰
      .replace(/<\/li>/gi, "\n")    // </li> -> ê°œí–‰
      .replace(/<li[^>]*>/gi, "- ")  // <li> -> "- "
      .replace(/<\/h[1-6]>/gi, "\n\n") // í—¤ë”© -> ë‘ ê°œí–‰
      .replace(/<h[1-6][^>]*>/gi, "")  // í—¤ë”© ì‹œì‘ íƒœê·¸ ì œê±°
  }

  // HTML íƒœê·¸ ì œê±°
  text = text.replace(/<[^>]*>/g, "")

  // HTML ì—”í‹°í‹° ë””ì½”ë”© (ìˆœì„œ ì¤‘ìš”: &amp;ë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì•¼ í•¨)
  text = text
    .replace(/&amp;/g, "&")  // ë¨¼ì € ì²˜ë¦¬
    .replace(/&quot;/g, '"')
    .replace(/&apos;/g, "'")
    .replace(/&lt;/g, "<")
    .replace(/&gt;/g, ">")
    .replace(/&nbsp;/g, " ")
    .replace(/&#39;/g, "'")
    .replace(/&#x27;/g, "'")
    .replace(/&#x2F;/g, "/")
    .replace(/&#10;/g, "\n")  // ê°œí–‰ ì—”í‹°í‹°
    .replace(/&#13;/g, "\r")  // ìºë¦¬ì§€ ë¦¬í„´

  if (preserveNewlines) {
    // ê°œí–‰ ë³´ì¡´ ëª¨ë“œ: ì—°ì†ëœ ê³µë°±ë§Œ ì •ë¦¬ (ê°œí–‰ì€ ìœ ì§€)
    // ì—°ì†ëœ ê³µë°±(ê°œí–‰ ì œì™¸)ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    text = text.replace(/[ \t]+/g, " ")
    // ì—°ì†ëœ ê°œí–‰ì„ ìµœëŒ€ 2ê°œë¡œ ì œí•œ
    text = text.replace(/\n{3,}/g, "\n\n")
    return text.trim() || undefined
  } else {
    // ê¸°ì¡´ ëª¨ë“œ: ëª¨ë“  ê³µë°±(ê°œí–‰ í¬í•¨)ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    text = text.replace(/\s+/g, " ").trim()
    return text || undefined
  }
}

// URLì—ì„œ Open Graph ì´ë¯¸ì§€ ì¶”ì¶œ
async function fetchImageFromUrl(url: string): Promise<string | undefined> {
  try {
    const response = await fetch(url, {
      headers: {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
      },
      next: { revalidate: 3600 }, // 1ì‹œê°„ ìºì‹œ
      signal: AbortSignal.timeout(5000), // 5ì´ˆ íƒ€ì„ì•„ì›ƒ
    })

    if (!response.ok) {
      return undefined
    }

    const html = await response.text()
    const baseUrl = new URL(url) // ì›ë³¸ URLì˜ base URL

    // ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ URLë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    const resolveUrl = (imageUrl: string): string => {
      // ì´ë¯¸ ì ˆëŒ€ URLì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
      if (imageUrl.startsWith("http://") || imageUrl.startsWith("https://")) {
        return imageUrl
      }
      // ìƒëŒ€ ê²½ë¡œë©´ base URLê³¼ ê²°í•©
      try {
        return new URL(imageUrl, baseUrl.origin).href
      } catch {
        return imageUrl
      }
    }

    // Open Graph ì´ë¯¸ì§€ ì¶”ì¶œ
    const ogImageMatch = html.match(/<meta\s+property=["']og:image["']\s+content=["']([^"']+)["']/i)
    if (ogImageMatch && ogImageMatch[1]) {
      return resolveUrl(ogImageMatch[1].trim())
    }

    // Twitter Card ì´ë¯¸ì§€ ì¶”ì¶œ (ëŒ€ì²´)
    const twitterImageMatch = html.match(/<meta\s+name=["']twitter:image["']\s+content=["']([^"']+)["']/i)
    if (twitterImageMatch && twitterImageMatch[1]) {
      return resolveUrl(twitterImageMatch[1].trim())
    }

    // ì¼ë°˜ ì´ë¯¸ì§€ ë©”íƒ€ íƒœê·¸ ì¶”ì¶œ
    const imageMatch = html.match(/<meta\s+name=["']image["']\s+content=["']([^"']+)["']/i)
    if (imageMatch && imageMatch[1]) {
      return resolveUrl(imageMatch[1].trim())
    }

    return undefined
  } catch (error) {
    // íƒ€ì„ì•„ì›ƒì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ
    return undefined
  }
}

const calculatePriority = (article: Omit<NormalizedArticle, "priority">): number => {
  const now = Date.now()
  const ageInHours = Math.max(0, (now - article.publishedAt.getTime()) / 36e5)
  const freshnessScore = Math.max(0, 100 - ageInHours * 4) // decay 4pts/hour
  const categoryWeight = CATEGORY_PRIORITY_WEIGHT[article.category] ?? 0
  const hasImageBonus = article.imageUrl ? 3 : 0
  return Math.round(freshnessScore + categoryWeight + hasImageBonus)
}

const dedupeArticles = (articles: NormalizedArticle[]): NormalizedArticle[] => {
  const seen = new Map<string, NormalizedArticle>()
  for (const article of articles) {
    const key = article.sourceUrl ?? article.title
    if (!seen.has(key)) {
      seen.set(key, article)
    }
  }
  return Array.from(seen.values())
}

async function persistArticles(articles: NormalizedArticle[]): Promise<NewsIngestResult> {
  let persisted = 0
  let skipped = 0

  for (const article of articles) {
    const uniqueFilters: Prisma.NewsWhereInput[] = []
    if (article.sourceUrl) {
      uniqueFilters.push({ sourceUrl: article.sourceUrl })
    }
    uniqueFilters.push({ title: article.title })

    const existing = await prisma.news.findFirst({
      where: { OR: uniqueFilters },
      select: { id: true },
    })

    if (existing) {
      skipped += 1
      continue
    }

    await prisma.news.create({
      data: {
        title: article.title,
        description: article.description,
        content: article.content,
        imageUrl: article.imageUrl,
        sourceUrl: article.sourceUrl,
        source: article.source,
        author: article.author,
        publishedAt: article.publishedAt,
        category: article.category,
        priority: article.priority,
        isTranslated: article.source === "NewsAPI" ? 1 : 0, // NewsAPIì—ì„œ ê°€ì ¸ì˜¨ ê¸°ì‚¬ëŠ” ë²ˆì—­ ì™„ë£Œë¡œ í‘œì‹œ
      },
    })
    persisted += 1
  }

  return { fetched: articles.length, persisted, skipped }
}

async function fetchNewsFromAPI(options: { category: NewsCategory; limit?: number }): Promise<NormalizedArticle[]> {
  if (!process.env[REQUIRED_ENV_KEY]) {
    console.warn(`âš ï¸  ${REQUIRED_ENV_KEY} ê°’ì´ ì—†ì–´ NewsAPI í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.`)
    return []
  }

  const url = new URL(NEWS_API_ENDPOINT)
  url.searchParams.set("apiKey", process.env[REQUIRED_ENV_KEY] as string)
  url.searchParams.set("country", NEWS_API_COUNTRY)
  url.searchParams.set("pageSize", String(options.limit ?? 20))
  url.searchParams.set("category", options.category)

  try {
    const response = await fetch(url, { next: { revalidate: 60 } })
    if (!response.ok) {
      throw new Error(`NewsAPI ìš”ì²­ ì‹¤íŒ¨: ${response.status}`)
    }

    const data = await response.json()
    const articles = (data.articles || []) as any[]

    // ë¨¼ì € ëª¨ë“  ê¸°ì‚¬ì˜ ì›ë¬¸ì„ ìˆ˜ì§‘
    const rawArticles = articles
      .map((item, index) => {
        // ì›ë³¸ ë°ì´í„° í™•ì¸ (ë””ë²„ê¹…ìš© - ì²« ë²ˆì§¸ ê¸°ì‚¬ë§Œ)
        if (index === 0) {
          console.log("ğŸ“° NewsAPI ì›ë³¸ ë°ì´í„° í™•ì¸:")
          console.log(`  - title ì›ë³¸:`, item.title?.substring(0, 100))
          console.log(`  - description ì›ë³¸:`, item.description?.substring(0, 100))
          console.log(`  - content ì›ë³¸:`, item.content?.substring(0, 200))
          console.log(`  - contentì— ê°œí–‰ ìˆìŒ:`, item.content?.includes("\n") || item.content?.includes("<br") || item.content?.includes("<p>"))
        }

        // ì œëª©ê³¼ ì„¤ëª…ì€ ê°œí–‰ ì œê±° (í•œ ì¤„ë¡œ)
        const title = stripHtmlTags(item.title, false) || sanitizeString(item.title)
        const sourceUrl = sanitizeString(item.url)

        if (!title || !sourceUrl) {
          return null
        }

        // contentëŠ” ê°œí–‰ ë³´ì¡´ (ë²ˆì—­ ì‹œ ê°œí–‰ ìœ ì§€)
        const description = stripHtmlTags(item.description, false) || sanitizeString(item.description)
        const content = stripHtmlTags(item.content, true) || sanitizeString(item.content)

        // ì²˜ë¦¬ í›„ ë°ì´í„° í™•ì¸ (ë””ë²„ê¹…ìš© - ì²« ë²ˆì§¸ ê¸°ì‚¬ë§Œ)
        if (index === 0) {
          console.log("ğŸ“ stripHtmlTags ì²˜ë¦¬ í›„:")
          console.log(`  - content ì²˜ë¦¬ í›„:`, content?.substring(0, 200))
          console.log(`  - contentì— ê°œí–‰ ìˆìŒ:`, content?.includes("\n"))
        }

        return {
          title,
          description,
          content,
          imageUrl: sanitizeString(item.urlToImage),
          sourceUrl,
          source: sanitizeString(item.source?.name) ?? "NewsAPI",
          author: sanitizeString(item.author),
          publishedAt: item.publishedAt ? new Date(item.publishedAt) : new Date(),
          category: options.category,
        }
      })
      .filter((item): item is Omit<NormalizedArticle, "priority"> => item !== null)

    // ëª¨ë“  ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë‚´ìš©ì„ ë³‘ë ¬ë¡œ ë²ˆì—­
    const translatedArticles = await Promise.all(
      rawArticles.map(async (article) => {
        const translatedTitle = await translateToKorean(article.title)
        const translatedDescription = await translateToKorean(article.description)
        const translatedContent = await translateToKorean(article.content)

        return {
          ...article,
          title: translatedTitle || article.title,
          description: translatedDescription || article.description,
          content: translatedContent || article.content,
        }
      })
    )

    // ê°œë°œì ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ developer ì¹´í…Œê³ ë¦¬ë¡œ ì¬ë¶„ë¥˜
    const categorizedArticles = translatedArticles.map((base) => {
      const finalCategory = detectDeveloperCategory(base) ? "developer" : base.category
      return {
        ...base,
        category: finalCategory,
        priority: calculatePriority({ ...base, category: finalCategory }),
      }
    })

    return categorizedArticles
  } catch (error) {
    console.error("Error fetching news from NewsAPI:", error)
    return []
  }
}

// Retry-After í—¤ë” íŒŒì‹± í—¬í¼ í•¨ìˆ˜
// Retry-AfterëŠ” ì •ìˆ˜(ì´ˆ) ë˜ëŠ” HTTP ë‚ ì§œ í˜•ì‹ì„ ê°€ì§ˆ ìˆ˜ ìˆìŒ
function parseRetryAfter(retryAfter: string | null): number | null {
  if (!retryAfter) return null

  const trimmed = retryAfter.trim()

  // ì •ìˆ˜ í˜•ì‹ì¸ì§€ í™•ì¸ (ìˆ«ìë¡œë§Œ êµ¬ì„±)
  if (/^\d+$/.test(trimmed)) {
    const seconds = Number.parseInt(trimmed, 10)
    return isNaN(seconds) ? null : seconds * 1000 // ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
  }

  // HTTP ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸ (ì˜ˆ: "Wed, 21 Oct 2015 07:28:00 GMT")
  const dateValue = Date.parse(trimmed)
  if (!isNaN(dateValue)) {
    const now = Date.now()
    const waitTime = dateValue - now
    // ê³¼ê±° ë‚ ì§œì´ê±°ë‚˜ ë„ˆë¬´ í° ê°’ì´ë©´ null ë°˜í™˜
    return waitTime > 0 && waitTime < 86400000 ? waitTime : null // ìµœëŒ€ 24ì‹œê°„
  }

  return null
}

// ë„¤ì´ë²„ API ìš”ì²­ ì¬ì‹œë„ í—¬í¼ í•¨ìˆ˜
async function fetchWithRetry(
  url: URL,
  headers: Record<string, string>,
  maxRetries = 3,
  baseDelay = 1000
): Promise<Response | null> {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await fetch(url, {
        headers,
        next: { revalidate: 60 },
      })

      if (response.status === 429) {
        // Rate limit ì´ˆê³¼ ì‹œ ëŒ€ê¸° ì‹œê°„ ê³„ì‚° (exponential backoff)
        const delay = baseDelay * Math.pow(2, attempt)
        const retryAfter = response.headers.get("Retry-After")
        const parsedWaitTime = parseRetryAfter(retryAfter)
        const waitTime = parsedWaitTime ?? delay

        // waitTimeì´ ìœ íš¨í•œì§€ í™•ì¸ (NaNì´ ì•„ë‹Œì§€)
        if (isNaN(waitTime) || waitTime <= 0) {
          console.warn(`âš ï¸  ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (429). Retry-After í—¤ë”ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë”œë ˆì´(${delay / 1000}ì´ˆ)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.`)
          if (attempt < maxRetries - 1) {
            await new Promise((resolve) => setTimeout(resolve, delay))
            continue
          } else {
            console.warn(`âš ï¸  ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (429). ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼.`)
            return null
          }
        }

        if (attempt < maxRetries - 1) {
          console.warn(`âš ï¸  ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (429). ${waitTime / 1000}ì´ˆ í›„ ì¬ì‹œë„... (${attempt + 1}/${maxRetries})`)
          await new Promise((resolve) => setTimeout(resolve, waitTime))
          continue
        } else {
          console.warn(`âš ï¸  ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (429). ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼.`)
          return null
        }
      }

      return response
    } catch (error) {
      if (attempt < maxRetries - 1) {
        const delay = baseDelay * Math.pow(2, attempt)
        console.warn(`âš ï¸  ë„¤ì´ë²„ API ìš”ì²­ ì˜¤ë¥˜. ${delay / 1000}ì´ˆ í›„ ì¬ì‹œë„... (${attempt + 1}/${maxRetries})`)
        await new Promise((resolve) => setTimeout(resolve, delay))
        continue
      }
      throw error
    }
  }
  return null
}

async function fetchNewsFromNaver(options: { category: NewsCategory; limit?: number }): Promise<NormalizedArticle[]> {
  const clientId = process.env[NAVER_CLIENT_ID_KEY]
  const clientSecret = process.env[NAVER_CLIENT_SECRET_KEY]

  if (!clientId || !clientSecret) {
    console.warn(`âš ï¸  ${NAVER_CLIENT_ID_KEY} ë˜ëŠ” ${NAVER_CLIENT_SECRET_KEY} ê°’ì´ ì—†ì–´ ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.`)
    return []
  }

  const queries = NAVER_CATEGORY_QUERIES[options.category] || ["ë‰´ìŠ¤"]
  const limitPerQuery = Math.ceil((options.limit ?? 20) / queries.length)
  const aggregated: NormalizedArticle[] = []

  for (let i = 0; i < queries.length; i++) {
    const query = queries[i]

    // ìš”ì²­ ê°„ ë”œë ˆì´ ì¶”ê°€ (ì²« ë²ˆì§¸ ìš”ì²­ ì œì™¸, ë„¤ì´ë²„ API rate limit ë°©ì§€)
    if (i > 0) {
      await new Promise((resolve) => setTimeout(resolve, 500)) // 500ms ë”œë ˆì´
    }

    try {
      const url = new URL(NAVER_SEARCH_API_ENDPOINT)
      url.searchParams.set("query", query)
      url.searchParams.set("display", String(Math.min(limitPerQuery, 100)))
      url.searchParams.set("start", "1")
      url.searchParams.set("sort", "sim") // ì •í™•ë„ìˆœ

      const headers = {
        "X-Naver-Client-Id": clientId,
        "X-Naver-Client-Secret": clientSecret,
      }

      const response = await fetchWithRetry(url, headers)

      if (!response) {
        // ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ í•´ë‹¹ ì¿¼ë¦¬ ê±´ë„ˆë›°ê¸°
        continue
      }

      if (!response.ok) {
        if (response.status === 403) {
          console.warn(`âš ï¸  ë„¤ì´ë²„ ê²€ìƒ‰ API ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ê°œë°œì ì„¼í„°ì—ì„œ ê²€ìƒ‰ APIë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.`)
        } else if (response.status !== 429) {
          // 429ëŠ” ì´ë¯¸ fetchWithRetryì—ì„œ ì²˜ë¦¬ë¨
          console.warn(`âš ï¸  ë„¤ì´ë²„ ê²€ìƒ‰ API ìš”ì²­ ì‹¤íŒ¨: ${response.status}`)
        }
        continue
      }

      const data = await response.json()
      const items = data.items || []

      // ë³‘ë ¬ë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ (ì„±ëŠ¥ ìµœì í™”)
      const itemsWithImages = await Promise.all(
        items.map(async (item: any) => {
          // HTML íƒœê·¸ ì œê±° ë° ì—”í‹°í‹° ë””ì½”ë”©
          // ë„¤ì´ë²„ APIëŠ” descriptionë§Œ ì œê³µí•˜ë¯€ë¡œ contentë¡œë„ ì‚¬ìš©
          const cleanTitle = stripHtmlTags(item.title, false) || sanitizeString(item.title)
          const cleanDescription = stripHtmlTags(item.description, true) || sanitizeString(item.description) // ê°œí–‰ ë³´ì¡´
          const sourceUrl = sanitizeString(item.originallink || item.link)

          if (!cleanTitle || !sourceUrl) return null

          // ì›ë¬¸ URLì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„
          let imageUrl: string | undefined = undefined
          try {
            imageUrl = await fetchImageFromUrl(sourceUrl)
          } catch (error) {
            // ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ
          }

          return {
            title: cleanTitle,
            description: cleanDescription,
            content: cleanDescription, // ë„¤ì´ë²„ APIëŠ” contentë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ description ì‚¬ìš©
            imageUrl,
            sourceUrl,
            source: sanitizeString(new URL(sourceUrl).hostname.replace("www.", "")) || "ë„¤ì´ë²„ ë‰´ìŠ¤",
            author: undefined, // ë„¤ì´ë²„ ê²€ìƒ‰ APIëŠ” ì‘ì„±ì ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
            publishedAt: item.pubDate ? new Date(item.pubDate) : new Date(),
            category: options.category,
          }
        })
      )

      // null ê°’ í•„í„°ë§ ë° íƒ€ì… ì•ˆì „ì„± í™•ë³´
      const validItems = itemsWithImages.filter(
        (item): item is Omit<NormalizedArticle, "priority"> => item !== null && item.title !== undefined
      )

      // ë„¤ì´ë²„ APIëŠ” í•œêµ­ì–´ ë‰´ìŠ¤ì´ë¯€ë¡œ ë²ˆì—­ ë¶ˆí•„ìš”
      for (const base of validItems) {
        // ê°œë°œì ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ developer ì¹´í…Œê³ ë¦¬ë¡œ ì¬ë¶„ë¥˜
        const finalCategory = detectDeveloperCategory(base) ? "developer" : base.category
        aggregated.push({
          ...base,
          category: finalCategory,
          priority: calculatePriority({ ...base, category: finalCategory }),
        })
      }
    } catch (error) {
      console.error(`Error fetching news from Naver API (query: ${query}):`, error)
    }
  }

  return aggregated
}

async function fetchFromRssFeeds(limitPerFeed = 10): Promise<NormalizedArticle[]> {
  const aggregated: NormalizedArticle[] = []

  for (const feed of RSS_FEEDS) {
    try {
      const response = await fetch(feed.url, { cache: "no-store" })
      if (!response.ok) {
        console.warn(`âš ï¸  RSS(${feed.url}) ìš”ì²­ ì‹¤íŒ¨: ${response.status}`)
        continue
      }

      const xml = await response.text()
      const parsed = xmlParser.parse(xml)
      const items =
        parsed?.rss?.channel?.item ||
        parsed?.feed?.entry ||
        parsed?.channel?.item ||
        []

      for (const item of items.slice(0, limitPerFeed)) {
        const rawTitle = item.title?.value || item.title
        const title = stripHtmlTags(rawTitle) || sanitizeString(rawTitle)
        const sourceUrl = sanitizeString(item.link?.href || item.link || item.guid)
        if (!title || !sourceUrl) continue

        const rawDescription = item.description?.value || item.description || item.summary
        const rawContent = item["content:encoded"] || item.content?.value || item.summary

        // contentëŠ” ê°œí–‰ ë³´ì¡´
        const description = stripHtmlTags(rawDescription, false) || sanitizeString(rawDescription)
        const content = stripHtmlTags(rawContent, true) || sanitizeString(rawContent)

        const base = {
          title,
          description,
          content,
          imageUrl: sanitizeString(item.enclosure?.url || item["media:content"]?.url),
          sourceUrl,
          source: sanitizeString(item.source?.value) ?? new URL(sourceUrl).hostname,
          author: sanitizeString(item.author?.name || item["dc:creator"]),
          publishedAt: item.pubDate ? new Date(item.pubDate) : new Date(),
          category: feed.category,
        }

        // RSS í”¼ë“œ ê¸°ì‚¬ ë²ˆì—­
        const translatedTitle = await translateToKorean(base.title)
        const translatedDescription = await translateToKorean(base.description)
        const translatedContent = await translateToKorean(base.content)

        const translatedBase = {
          ...base,
          title: translatedTitle || base.title,
          description: translatedDescription || base.description,
          content: translatedContent || base.content,
        }

        // ê°œë°œì ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ developer ì¹´í…Œê³ ë¦¬ë¡œ ì¬ë¶„ë¥˜
        const finalCategory = detectDeveloperCategory(translatedBase) ? "developer" : translatedBase.category
        aggregated.push({
          ...translatedBase,
          category: finalCategory,
          priority: calculatePriority({ ...translatedBase, category: finalCategory }),
        })
      }
    } catch (error) {
      console.error("Error parsing RSS feed:", feed.url, error)
    }
  }

  return aggregated
}

export async function ingestLatestNews(options?: {
  categories?: NewsCategory[]
  limitPerCategory?: number
  includeRss?: boolean
  includeNaver?: boolean
  rssLimit?: number
}): Promise<NewsIngestResult> {
  const categories = options?.categories ?? SUPPORTED_NEWS_CATEGORIES
  const limitPerCategory = options?.limitPerCategory ?? 20
  const includeRss = options?.includeRss ?? true
  const includeNaver = options?.includeNaver ?? true

  const collected: NormalizedArticle[] = []

  for (const category of categories) {
    // NewsAPIì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    const apiArticles = await fetchNewsFromAPI({ category, limit: limitPerCategory })
    collected.push(...apiArticles)

    // ë„¤ì´ë²„ ê²€ìƒ‰ APIì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    if (includeNaver) {
      const naverArticles = await fetchNewsFromNaver({ category, limit: limitPerCategory })
      collected.push(...naverArticles)
    }
  }

  if (includeRss) {
    const rssArticles = await fetchFromRssFeeds(options?.rssLimit ?? 8)
    collected.push(...rssArticles)
  }

  const deduped = dedupeArticles(collected)
  return persistArticles(deduped)
}

export async function getNews(query: NewsQuery = {}) {
  try {
    const { page, limit, sort } = { ...DEFAULT_QUERY, ...query }
    const skip = (page - 1) * limit

    const where: Prisma.NewsWhereInput = {}
    if (query.category && query.category !== "all" && query.category !== "general") {
      where.category = query.category
    }
    if (query.search) {
      const search = query.search
      // PostgreSQLê³¼ SQLiteëŠ” case-sensitiveê°€ ê¸°ë³¸ì´ë¯€ë¡œ mode: "insensitive" í•„ìš”
      // MySQLì€ ê¸°ë³¸ì ìœ¼ë¡œ case-insensitiveì´ë¯€ë¡œ mode ì˜µì…˜ ë¶ˆí•„ìš”
      const dbUrl = process.env.DATABASE_URL || ""
      const isPostgreSQL = dbUrl.startsWith("postgresql://") || dbUrl.startsWith("postgres://")
      const isSQLite = dbUrl.startsWith("file:") || dbUrl.startsWith("sqlite:")
      const useInsensitive = isPostgreSQL || isSQLite

      if (useInsensitive) {
        // PostgreSQL/SQLite: case-insensitive ê²€ìƒ‰ í•„ìš”
        where.OR = [
          { title: { contains: search, mode: "insensitive" } as Prisma.StringFilter<"News"> },
          { description: { contains: search, mode: "insensitive" } as Prisma.StringNullableFilter<"News"> },
          { content: { contains: search, mode: "insensitive" } as Prisma.StringNullableFilter<"News"> },
        ]
      } else {
        // MySQL: ê¸°ë³¸ì ìœ¼ë¡œ case-insensitive
        where.OR = [
          { title: { contains: search } },
          { description: { contains: search } },
          { content: { contains: search } },
        ]
      }
    }
    if (typeof query.minPriority === "number") {
      where.priority = { gte: query.minPriority }
    }

    const orderBy: Prisma.NewsOrderByWithRelationInput[] = []
    if (sort === "priority") {
      orderBy.push({ priority: "desc" })
    } else if (sort === "popular") {
      orderBy.push({ readHistory: { _count: "desc" } })
    }
    orderBy.push({ publishedAt: "desc" })

    const [news, total] = await Promise.all([
      prisma.news.findMany({
        where,
        orderBy,
        skip,
        take: limit,
      }),
      prisma.news.count({ where }),
    ])

    return {
      news,
      pagination: {
        total,
        page,
        limit,
        pages: Math.ceil(total / limit),
      },
    }
  } catch (error) {
    console.error("Error getting news:", error)
    return { news: [], pagination: { total: 0, page: 1, limit: query.limit ?? DEFAULT_QUERY.limit, pages: 0 } }
  }
}

export async function getNewsDetail(newsId: string) {
  try {
    return await prisma.news.findUnique({
      where: { id: newsId },
      include: {
        readHistory: true,
      },
    })
  } catch (error) {
    console.error("Error getting news detail:", error)
    return null
  }
}

export async function searchNews(query: string, page = 1, limit = 10) {
  return getNews({ search: query, page, limit })
}
